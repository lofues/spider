{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 编写爬虫爬去二手房100页的数据:平米 名字 楼层   并保存到数据库和csv文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1页正在抓取\n",
      "第1页抓取成功\n",
      "第2页正在抓取\n",
      "第2页抓取成功\n",
      "第3页正在抓取\n",
      "第3页抓取成功\n",
      "第4页正在抓取\n",
      "第4页抓取成功\n",
      "第5页正在抓取\n",
      "第5页抓取成功\n",
      "第6页正在抓取\n",
      "第6页抓取成功\n",
      "第7页正在抓取\n",
      "第7页抓取成功\n",
      "第8页正在抓取\n",
      "第8页抓取成功\n",
      "第9页正在抓取\n",
      "第9页抓取成功\n",
      "第10页正在抓取\n",
      "第10页抓取成功\n",
      "第11页正在抓取\n",
      "第11页抓取成功\n",
      "第12页正在抓取\n",
      "第12页抓取成功\n",
      "第13页正在抓取\n",
      "第13页抓取成功\n",
      "第14页正在抓取\n",
      "第14页抓取成功\n",
      "第15页正在抓取\n",
      "第15页抓取成功\n",
      "第16页正在抓取\n",
      "第16页抓取成功\n",
      "第17页正在抓取\n",
      "第17页抓取成功\n",
      "第18页正在抓取\n",
      "第18页抓取成功\n",
      "第19页正在抓取\n",
      "第19页抓取成功\n",
      "第20页正在抓取\n",
      "第20页抓取成功\n",
      "第21页正在抓取\n",
      "第21页抓取成功\n",
      "第22页正在抓取\n",
      "第22页抓取成功\n",
      "第23页正在抓取\n",
      "第23页抓取成功\n",
      "第24页正在抓取\n",
      "第24页抓取成功\n",
      "第25页正在抓取\n",
      "第25页抓取成功\n",
      "第26页正在抓取\n",
      "第26页抓取成功\n",
      "第27页正在抓取\n",
      "第27页抓取成功\n",
      "第28页正在抓取\n",
      "第28页抓取成功\n",
      "第29页正在抓取\n",
      "第29页抓取成功\n",
      "第30页正在抓取\n",
      "第30页抓取成功\n",
      "第31页正在抓取\n",
      "第31页抓取成功\n",
      "第32页正在抓取\n",
      "第32页抓取成功\n",
      "第33页正在抓取\n",
      "第33页抓取成功\n",
      "第34页正在抓取\n",
      "第34页抓取成功\n",
      "第35页正在抓取\n",
      "第35页抓取成功\n",
      "第36页正在抓取\n",
      "第36页抓取成功\n",
      "第37页正在抓取\n",
      "第37页抓取成功\n",
      "第38页正在抓取\n",
      "第38页抓取成功\n",
      "第39页正在抓取\n",
      "第39页抓取成功\n",
      "第40页正在抓取\n",
      "第40页抓取成功\n",
      "第41页正在抓取\n",
      "第41页抓取成功\n",
      "第42页正在抓取\n",
      "第42页抓取成功\n",
      "第43页正在抓取\n",
      "第43页抓取成功\n",
      "第44页正在抓取\n",
      "第44页抓取成功\n",
      "第45页正在抓取\n",
      "第45页抓取成功\n",
      "第46页正在抓取\n",
      "第46页抓取成功\n",
      "第47页正在抓取\n",
      "第47页抓取成功\n",
      "第48页正在抓取\n",
      "第48页抓取成功\n",
      "第49页正在抓取\n",
      "第49页抓取成功\n",
      "第50页正在抓取\n",
      "第50页抓取成功\n",
      "第51页正在抓取\n",
      "第51页抓取成功\n",
      "第52页正在抓取\n",
      "第52页抓取成功\n",
      "第53页正在抓取\n",
      "第53页抓取成功\n",
      "第54页正在抓取\n",
      "第54页抓取成功\n",
      "第55页正在抓取\n",
      "第55页抓取成功\n",
      "第56页正在抓取\n",
      "第56页抓取成功\n",
      "第57页正在抓取\n",
      "第57页抓取成功\n",
      "第58页正在抓取\n",
      "第58页抓取成功\n",
      "第59页正在抓取\n",
      "第59页抓取成功\n",
      "第60页正在抓取\n",
      "第60页抓取成功\n",
      "第61页正在抓取\n",
      "第61页抓取成功\n",
      "第62页正在抓取\n",
      "第62页抓取成功\n",
      "第63页正在抓取\n",
      "第63页抓取成功\n",
      "第64页正在抓取\n",
      "第64页抓取成功\n",
      "第65页正在抓取\n",
      "第65页抓取成功\n",
      "第66页正在抓取\n",
      "第66页抓取成功\n",
      "第67页正在抓取\n",
      "第67页抓取成功\n",
      "第68页正在抓取\n",
      "第68页抓取成功\n",
      "第69页正在抓取\n",
      "第69页抓取成功\n",
      "第70页正在抓取\n",
      "第70页抓取成功\n",
      "第71页正在抓取\n",
      "第71页抓取成功\n",
      "第72页正在抓取\n",
      "第72页抓取成功\n",
      "第73页正在抓取\n",
      "第73页抓取成功\n",
      "第74页正在抓取\n",
      "第74页抓取成功\n",
      "第75页正在抓取\n",
      "第75页抓取成功\n",
      "第76页正在抓取\n",
      "第76页抓取成功\n",
      "第77页正在抓取\n",
      "第77页抓取成功\n",
      "第78页正在抓取\n",
      "第78页抓取成功\n",
      "第79页正在抓取\n",
      "第79页抓取成功\n",
      "第80页正在抓取\n",
      "第80页抓取成功\n",
      "第81页正在抓取\n",
      "第81页抓取成功\n",
      "第82页正在抓取\n",
      "第82页抓取成功\n",
      "第83页正在抓取\n",
      "第83页抓取成功\n",
      "第84页正在抓取\n",
      "第84页抓取成功\n",
      "第85页正在抓取\n",
      "第85页抓取成功\n",
      "第86页正在抓取\n",
      "第86页抓取成功\n",
      "第87页正在抓取\n",
      "第87页抓取成功\n",
      "第88页正在抓取\n",
      "第88页抓取成功\n",
      "第89页正在抓取\n",
      "第89页抓取成功\n",
      "第90页正在抓取\n",
      "第90页抓取成功\n",
      "第91页正在抓取\n",
      "第91页抓取成功\n",
      "第92页正在抓取\n",
      "第92页抓取成功\n",
      "第93页正在抓取\n",
      "第93页抓取成功\n",
      "第94页正在抓取\n",
      "第94页抓取成功\n",
      "第95页正在抓取\n",
      "第95页抓取成功\n",
      "第96页正在抓取\n",
      "第96页抓取成功\n",
      "第97页正在抓取\n",
      "第97页抓取成功\n",
      "第98页正在抓取\n",
      "第98页抓取成功\n",
      "第99页正在抓取\n",
      "第99页抓取成功\n",
      "第100页正在抓取\n",
      "第100页抓取成功\n",
      "房源总数： 3000\n",
      "保存csv文件成功\n",
      "CPU times: user 6.31 s, sys: 134 ms, total: 6.45 s\n",
      "Wall time: 1min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import threading\n",
    "import time\n",
    "import requests\n",
    "import urllib\n",
    "import re\n",
    "import lxml\n",
    "import time\n",
    "import random\n",
    "import fake_useragent\n",
    "import pymysql\n",
    "import csv\n",
    "\n",
    "ua = fake_useragent.UserAgent()\n",
    "\n",
    "class LianjiaSpider(object):\n",
    "    def __init__(self):\n",
    "        self.url = 'https://bj.lianjia.com/ershoufang/pg{}/'\n",
    "        self.db = pymysql.connect('localhost','lofues','123456','spider')\n",
    "        self.cursor = self.db.cursor()\n",
    "        self.info = []\n",
    "        self.test = 1\n",
    "        \n",
    "    def get_html(self,url):\n",
    "        headers = {'User-Agent':ua.random}\n",
    "        # 尝试三次，否则换一页地址\n",
    "        if self.test <= 3:\n",
    "            try:\n",
    "                html = requests.get(url=url,headers=headers,timeout=3).text\n",
    "                self.parse_html(html)\n",
    "                self.test = 1\n",
    "            except Exception as e:\n",
    "                print('获取页面失败',e)\n",
    "                self.test += 1\n",
    "                self.get_html(url)\n",
    "                \n",
    "    # 解析页面\n",
    "    def parse_html(self,html):\n",
    "        lxml_html = lxml.etree.HTML(html)\n",
    "        lis = lxml_html.xpath('//ul[@class=\"sellListContent\"]//li')\n",
    "        for li in lis:\n",
    "            house = []\n",
    "\n",
    "            # 获取房屋名称\n",
    "            house_name = li.xpath('.//div[@class=\"title\"]/a/text()')[0].strip()\n",
    "        #         print('house_name:',house_name)\n",
    "\n",
    "            # 获取房屋地址\n",
    "            house_address = li.xpath('.//div[@class=\"address\"]/div/a/text()')[0].strip()\n",
    "        #         print('house_adress:',house_address)\n",
    "\n",
    "            # 获取房屋的房间数,面积,朝向,是否精装\n",
    "            house_info = li.xpath('.//div[@class=\"houseInfo\"]/text()')[0].strip()\n",
    "        #         print('house_info:',house_info)\n",
    "\n",
    "            house_info = house_info.split('|')\n",
    "            if len(house_info) == 5:\n",
    "\n",
    "                room_number = house_info[1].strip()\n",
    "                house_area = house_info[2].strip()[:-2]\n",
    "                house_direcation = house_info[3].strip()\n",
    "                house_perfect = house_info[4].strip()\n",
    "        #             print('room_number,area,direction,perfect:',room_number,type(house_area),house_direcation,house_perfect)\n",
    "\n",
    "            # 获取层数\n",
    "            house_flood = li.xpath('.//div[@class=\"flood\"]/div/text()')[0].strip()\n",
    "            house_flood = house_flood.strip(' -')\n",
    "        #         print('house_flood:',house_flood)\n",
    "\n",
    "            # 获取小区名称\n",
    "            district_name = li.xpath('.//div[@class=\"flood\"]/div/a/text()')[0].strip()\n",
    "        #         print('district_name:',district_name)\n",
    "\n",
    "            # 获取小区总价\n",
    "            total_price = li.xpath('.//div[@class=\"priceInfo\"]/div[1]/span/text()')[0].strip()\n",
    "        #         print('total_price:',type(total_price))\n",
    "\n",
    "            # 获取小区单价\n",
    "            unit_price = li.xpath('.//div[@class=\"priceInfo\"]/div[2]/span/text()')[0].strip()\n",
    "            unit_price = unit_price.split('/')[0][2:-1]\n",
    "        #         print('unit_price:',type(unit_price))\n",
    "\n",
    "            house = [house_name,house_address,room_number,house_area,house_direcation,house_perfect,\n",
    "                    house_flood,district_name,total_price,unit_price]\n",
    "        #         print(house)\n",
    "            self.info.append(house)\n",
    "    \n",
    "    def save_mysql(self,houses):\n",
    "        ins = 'insert into lianjiahouse(name,address,room,area,direction,perfect,floor,district,total_price,unit_price) values(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)'\n",
    "        try:\n",
    "            self.cursor.executemany(ins,self.info)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            self.db.rollback()\n",
    "        self.db.commit()\n",
    "        \n",
    "    def save_csv(self,houses):\n",
    "        header = ['个数','名称','地址','房间数','面积','朝向','是否精装','层数','小区名称','总价','单价']\n",
    "        with open('lianjiahouses.csv','w',encoding='utf-8') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(header)\n",
    "            \n",
    "            for i,house in enumerate(houses):\n",
    "                writer.writerow([i+1] + house)\n",
    "        print('保存csv文件成功')\n",
    "            \n",
    "        \n",
    "            \n",
    "    def run(self):\n",
    "        for i in range(1,101):\n",
    "            print('第{}页正在抓取'.format(i))\n",
    "            url = self.url.format(i)\n",
    "            self.get_html(url)\n",
    "            print('第{}页抓取成功'.format(i))\n",
    "            time.sleep(random.random())\n",
    "\n",
    "#         print(self.info)\n",
    "        print('房源总数：',len(self.info))\n",
    "#         self.save_mysql(self.info)\n",
    "        self.save_csv(self.info)\n",
    "        \n",
    "        # 关闭数据库连接\n",
    "        self.cursor.close()\n",
    "        self.db.close()\n",
    "\n",
    "spider = LianjiaSpider()\n",
    "spider.run()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function writerow:\n",
      "\n",
      "writerow(...) method of _csv.writer instance\n",
      "    writerow(iterable)\n",
      "    \n",
      "    Construct and write a CSV record from an iterable of fields.  Non-string\n",
      "    elements will be converted to string.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "f = open('s.x','w')\n",
    "writter = csv.writer(f)\n",
    "help(writter.writerow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
