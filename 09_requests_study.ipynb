{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用requests模块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'http://www.baidu.com/'\n",
    "headers = {'User-Agent':'Mozilla/5.0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = requests.get(url=url,headers=headers)\n",
    "\n",
    "# 获取响应的编码格式并设置\n",
    "res.encoding = 'utf-8'\n",
    "\n",
    "# 字符串类型 结构数据\n",
    "html = res.text \n",
    "\n",
    "# bytes类型\n",
    "content = res.content # bytes数据类型\n",
    "\n",
    "# http响应码 非结构数据\n",
    "code = res.status_code\n",
    "\n",
    "# 返回实际数据的url地址(重定向的最终地址)\n",
    "\n",
    "# print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "请输入你想要爬取的名字:法轮大法\n",
      "图片个数: 24\n",
      "jpg\n",
      "第1张图片正在抓取\n",
      "jpg\n",
      "第2张图片正在抓取\n",
      "jpg\n",
      "第3张图片正在抓取jpg\n",
      "\n",
      "第4张图片正在抓取jpg\n",
      "\n",
      "第5张图片正在抓取jpg\n",
      "第6张图片正在抓取\n",
      "jpg\n",
      "\n",
      "第7张图片正在抓取\n",
      "jpg\n",
      "第8张图片正在抓取jpg\n",
      "\n",
      "第9张图片正在抓取jpg\n",
      "\n",
      "第10张图片正在抓取jpg\n",
      "\n",
      "第11张图片正在抓取\n",
      "jpg\n",
      "第12张图片正在抓取jpg\n",
      "\n",
      "第13张图片正在抓取jpg\n",
      "\n",
      "第14张图片正在抓取jpg\n",
      "\n",
      "第15张图片正在抓取jpg\n",
      "\n",
      "第16张图片正在抓取jpg\n",
      "\n",
      "第17张图片正在抓取\n",
      "jpg\n",
      "第18张图片正在抓取\n",
      "jpg\n",
      "第19张图片正在抓取\n",
      "jpg\n",
      "第20张图片正在抓取jpg\n",
      "第21张图片正在抓取jpg\n",
      "\n",
      "第22张图片正在抓取\n",
      "jpg\n",
      "\n",
      "第23张图片正在抓取jpg\n",
      "\n",
      "第24张图片正在抓取\n",
      "第1张图片抓取成功\n",
      "第4张图片抓取成功第2张图片抓取成功\n",
      "\n",
      "第8张图片抓取成功\n",
      "第3张图片抓取成功\n",
      "第6张图片抓取成功\n",
      "第5张图片抓取成功\n",
      "第12张图片抓取成功第10张图片抓取成功\n",
      "第9张图片抓取成功第11张图片抓取成功\n",
      "\n",
      "\n",
      "第7张图片抓取成功\n",
      "第13张图片抓取成功\n",
      "第14张图片抓取成功\n",
      "第15张图片抓取成功\n",
      "第16张图片抓取成功第17张图片抓取成功\n",
      "\n",
      "第18张图片抓取成功\n",
      "第19张图片抓取成功\n",
      "第21张图片抓取成功\n",
      "第24张图片抓取成功第20张图片抓取成功\n",
      "\n",
      "第22张图片抓取成功\n",
      "第23张图片抓取成功\n",
      "抓取所有图片成功\n",
      "CPU times: user 301 ms, sys: 44.9 ms, total: 346 ms\n",
      "Wall time: 4.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from urllib import parse\n",
    "import requests\n",
    "import re,time,random\n",
    "import fake_useragent\n",
    "import os\n",
    "import threading\n",
    "\n",
    "\n",
    "one_url = \"https://image.baidu.com/search/index?tn=baiduimage&word={}\"\n",
    "class BaiduImageSpider(object):\n",
    "    def __init__(self):\n",
    "        self.url = 'https://image.baidu.com/search/index?tn=baiduimage&word={}'\n",
    "    \n",
    "    def get_ua(self):\n",
    "        ua = fake_useragent.UserAgent()\n",
    "        agent = ua.random\n",
    "        return agent\n",
    "    \n",
    "    def get_image(self, name):\n",
    "        name_quote = parse.quote(name)\n",
    "        url = self.url.format(name_quote)\n",
    "        html = requests.get(url=url,headers={'User-Agent':self.get_ua()}).text\n",
    "        \n",
    "        pattern = re.compile(r'\"hoverURL\":\"(.*?)\"', re.S)\n",
    "        # link_list: ['', '', '','',...]\n",
    "        link_list = pattern.findall(html)\n",
    "        link_list = [link for link in link_list if link != '' and link[6] == '/']\n",
    "#         for i in link_list:\n",
    "#             print(i)\n",
    "        print('图片个数:',len(link_list))\n",
    "        \n",
    "        # 创建对应的文件夹\n",
    "        filename = '/home/tarena/images/{}/'.format(name)\n",
    "        if not os.path.exists(filename):\n",
    "            os.makedirs(filename)\n",
    "        \n",
    "        thread_list = []\n",
    "        for i,link in enumerate(link_list):\n",
    "            image_type = link.split('.')[-1]\n",
    "            print(image_type)\n",
    "            image_filename = filename + '{}_{}.'.format(name,i+1) + image_type\n",
    "            thread = threading.Thread(target=self.save_image,args=(link,image_filename,i+1))\n",
    "            thread_list.append(thread)\n",
    "            thread.start()\n",
    "#             self.save_image(link,image_filename,i+1)\n",
    "#             time.sleep(random.random())\n",
    "    \n",
    "        for thread in thread_list:\n",
    "            thread.join()\n",
    "            \n",
    "    def save_image(self,url,filename,num):\n",
    "        print('第{}张图片正在抓取'.format(num))\n",
    "        content = requests.get(url,headers={'User-Agent':self.get_ua()}).content\n",
    "        with open(filename,'wb') as f:\n",
    "            f.write(content)\n",
    "        print('第{}张图片抓取成功'.format(num))\n",
    "        \n",
    "    def run(self):\n",
    "        name = input('请输入你想要爬取的名字:')\n",
    "        self.get_image(name)\n",
    "        print(\"抓取所有图片成功\")\n",
    "        \n",
    "spider = BaiduImageSpider()\n",
    "spider.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xpath工具的使用"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
